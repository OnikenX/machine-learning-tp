{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados\n",
    "Foi se usado os dados que foram processados na meta anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fixed_acidity</th>\n",
       "      <th>Volatile_acidity</th>\n",
       "      <th>Citric_acid</th>\n",
       "      <th>Residual_sugar</th>\n",
       "      <th>Chlorides</th>\n",
       "      <th>Free_sulfur_dioxide</th>\n",
       "      <th>Total_sulfur_dioxide</th>\n",
       "      <th>Density</th>\n",
       "      <th>Ph</th>\n",
       "      <th>Sulphates</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Red_wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5315</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5316</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5317</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5318</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5319</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5320 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fixed_acidity  Volatile_acidity  Citric_acid  Residual_sugar  Chlorides  \\\n",
       "0               7.4              0.70         0.00             1.9      0.076   \n",
       "1               7.8              0.88         0.00             2.6      0.098   \n",
       "2               7.8              0.76         0.04             2.3      0.092   \n",
       "3              11.2              0.28         0.56             1.9      0.075   \n",
       "4               7.4              0.66         0.00             1.8      0.075   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "5315            6.2              0.21         0.29             1.6      0.039   \n",
       "5316            6.6              0.32         0.36             8.0      0.047   \n",
       "5317            6.5              0.24         0.19             1.2      0.041   \n",
       "5318            5.5              0.29         0.30             1.1      0.022   \n",
       "5319            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      Free_sulfur_dioxide  Total_sulfur_dioxide  Density    Ph  Sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    13.0                  40.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "5315                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "5316                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "5317                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "5318                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "5319                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      Alcohol  Red_wine  \n",
       "0         9.4       1.0  \n",
       "1         9.8       1.0  \n",
       "2         9.8       1.0  \n",
       "3         9.8       1.0  \n",
       "4         9.4       1.0  \n",
       "...       ...       ...  \n",
       "5315     11.2       0.0  \n",
       "5316      9.6       0.0  \n",
       "5317      9.4       0.0  \n",
       "5318     12.8       0.0  \n",
       "5319     11.8       0.0  \n",
       "\n",
       "[5320 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "wines = pd.read_csv('merged.csv', sep=',')\n",
    "wines['Quality'] = np.where(wines.Quality >= 7, 1, 0)\n",
    "X = wines.drop(columns='Quality')\n",
    "y = wines['Quality']\n",
    "X_train , X_test, y_train , y_test = train_test_split(X, y, test_size = 0.1)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo a usar\n",
    "\n",
    "Depois de lido o [este artigo](https://medium.com/thinkport/top-10-binary-classification-algorithms-a-beginners-guide-feeacbd7a3e2), dicidiu se usar o **VotingClassifier** para e os vários algoritmos também testados sozinhos, estes sendo o **naive bias**, **logistic regression**, **random forest** e o **vector machine**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 0.004573822021484375 segundos\n",
      "score on test: 0.7406015037593985\n",
      "score on train: 0.7445697577276524\n"
     ]
    }
   ],
   "source": [
    "#inclusão do naive bias\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "start = time.time()\n",
    "mnb.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "print(\"time taken:\",end - start,\"segundos\")\n",
    "print(\"score on test: \" + str(mnb.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(mnb.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 0.49903368949890137 segundos\n",
      "score on test: 0.8120300751879699\n",
      "score on train: 0.8235171261487051\n"
     ]
    }
   ],
   "source": [
    "#inclusão do logistic regression com uma iteração maxima de 1000\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression(max_iter=1000)\n",
    "\n",
    "start = time.time()\n",
    "lr.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "print(\"time taken:\",end - start,\"segundos\")\n",
    "print(\"score on test: \" + str(lr.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(lr.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 0.2126603126525879 segundos\n",
      "score on test: 0.8439849624060151\n",
      "score on train: 0.9068504594820385\n"
     ]
    }
   ],
   "source": [
    "#inclusão do Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# n_estimators = number of decision trees\n",
    "rf = RandomForestClassifier(n_estimators=30, max_depth=9)\n",
    "\n",
    "start = time.time()\n",
    "rf.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "print(\"time taken:\",end - start,\"segundos\")\n",
    "print(\"score on test: \" + str(rf.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 0.11390161514282227 segundos\n",
      "score on test: 0.7913533834586466\n",
      "score on train: 0.8124477861319966\n"
     ]
    }
   ],
   "source": [
    "#finalmente inclusão do vector machine com o parapetro de regularização a 0.0001 sendo este o recomendado \n",
    "from sklearn.svm import LinearSVC\n",
    "svm=LinearSVC(C=0.0001)\n",
    "\n",
    "start = time.time()\n",
    "svm.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "print(\"time taken:\",end - start,\"segundos\")\n",
    "print(\"score on test: \" + str(svm.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(svm.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 0.7756657600402832 segundos\n",
      "score on test: 0.8082706766917294\n",
      "score on train: 0.8239348370927319\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "# 1) naive bias = mnb\n",
    "mnb = MultinomialNB()\n",
    "# 2) logistic regression =lr\n",
    "lr=LogisticRegression(max_iter=1000)\n",
    "# 3) random forest =rf\n",
    "rf = RandomForestClassifier(n_estimators=30, max_depth=9)\n",
    "# 4) support vector machine = svm\n",
    "svm=LinearSVC(C=0.0001)\n",
    "\n",
    "evc=VotingClassifier(estimators=[('mnb',mnb),('lr',lr),('rf',rf),('svm',svm)],voting='hard')\n",
    "\n",
    "start = time.time()\n",
    "evc.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "print(\"time taken:\",end - start,\"segundos\")\n",
    "print(\"score on test: \" + str(evc.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(evc.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de executados todos os algoritmos o que mostrou melhores resultados para o caso em questão foi o **RandomForestClassifier** com o menor tempo, 0.2s e com os melhores resultados, 90% de *score*."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
